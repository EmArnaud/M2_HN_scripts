{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import json\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.tokenizer import Tokenizer\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouverture des fichiers annotés et séparation en deux sous-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus_annote/doccano_serie0.jsonl', encoding='utf-8') as f:\n",
    "    result = [json.loads(jline) for jline in f.read().splitlines()]\n",
    "\n",
    "random.shuffle(result)\n",
    "training_corpus = result[:220]\n",
    "test_corpus = result[220:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training(TRAIN_DATA):\n",
    "    db = DocBin()\n",
    "    for training_example in TRAIN_DATA:\n",
    "        text = training_example['data']\n",
    "        labels = training_example['label']\n",
    "        doc = nlp.make_doc(text)\n",
    "        ents = []\n",
    "        for start, end, label in labels:\n",
    "            span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "            if span is None:\n",
    "                print(\"Skipping entity\")\n",
    "            else:\n",
    "                ents.append(span)\n",
    "        doc.ents = ents \n",
    "        db.add(doc)\n",
    "    print(len(db))\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = create_training(training_corpus)\n",
    "train.to_disk(\"train_serie1.spacy\")\n",
    "\n",
    "valid = create_training(test_corpus)\n",
    "valid.to_disk(\"valid_serie1.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init fill-config configs/base_config.cfg configs/config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[+] Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "[i] Pipeline: ['tok2vec', 'ner']\n",
      "[i] Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00    154.50    0.31    0.18    1.13    0.00\n",
      "  0     200       8953.36  13278.15    5.84   11.67    3.89    0.06\n",
      "  1     400        835.93   5396.31   32.78   45.21   25.72    0.33\n",
      "  2     600        501.31   4796.94   36.30   33.64   39.42    0.36\n",
      "  3     800        159.49   4445.30   38.51   68.76   26.75    0.39\n",
      "  4    1000        117.74   3228.30   36.17   68.01   24.64    0.36\n",
      "  5    1200        217.04   4170.59   39.56   46.88   34.21    0.40\n",
      "  6    1400        209.38   3653.36   41.74   57.24   32.85    0.42\n",
      "  7    1600        628.28   3299.07   42.54   40.07   45.33    0.43\n",
      "  8    1800        654.93   3379.28   40.14   45.28   36.04    0.40\n",
      "  9    2000        570.34   3592.26   44.77   49.91   40.59    0.45\n",
      " 10    2200        759.32   2832.95   39.42   47.13   33.88    0.39\n",
      " 10    2400        364.41   2975.88   42.25   56.92   33.60    0.42\n",
      " 11    2600        620.28   2921.85   42.31   52.32   35.52    0.42\n",
      " 12    2800        696.83   3331.90   42.75   43.93   41.62    0.43\n",
      " 13    3000        479.73   2463.75   43.62   50.43   38.43    0.44\n",
      " 14    3200        698.80   3226.79   42.23   50.42   36.32    0.42\n",
      " 15    3400        809.90   2723.18   41.74   57.96   32.61    0.42\n",
      " 16    3600        572.72   2217.36   42.56   49.97   37.07    0.43\n",
      "[+] Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 16:43:09.469678: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-03-03 16:43:09.469710: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Set up nlp object from config\n",
      "Pipeline: ['tok2vec', 'ner']\n",
      "Created vocabulary\n",
      "Added vectors: fr_core_news_lg\n",
      "Finished initializing nlp object\n",
      "Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train configs/config.cfg --output ./output --paths.train ./train_serie1.spacy --paths.dev ./valid_serie1.spacy\n",
    "#43 minutes to run (16go RAM et quadcore mais pas de multiprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_ner = spacy.load(\"output/model-best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_adm = [\"commune\", \"Commune\", \"district\", \"Département\", \"département\", \"départemens\", \"Départemens\", \"municipalité\", \"Municipalité\", \"ville\", \"village\", \"canton\"\n",
    "         ]\n",
    "structures_adm2 = [\"commune\", \"Commune\", \"district\", \"Département\", \"département\", \"départemens\", \"Départemens\", \"municipalité\", \"Municipalité\", \"ville\", \"village\", \"canton\"\n",
    "         ]\n",
    "lieux = ['Basse-Alpes', 'Maine-&-Loire', 'Seine', 'Alpes-maritimes', 'Arriége', 'Charente-inférieure', 'Côte-d\\'or', 'Côtes-du-Nord', 'Dyle', 'Escaut', 'Finistère', 'Forêts', 'Haute-Garonne', 'Ille-et-vilaine', 'Indre-et-Loire', 'Jemmapes', 'Loire-inférieure', 'Lys', 'Meurthe', 'Meuse-inférieure', 'Deux-Nèthes', 'Ourthe', 'Puy-de-Dôme', 'Basses-Pyrénées', 'Pyrénées-Orientales', 'Sambre-et-Meuse', 'Haute-Saone', 'Saone-et-Loire', 'Seine-inférieure', 'Deux-Sèvres', 'La Souterraine', 'Alès', 'Moulins-Engilbert', 'Segré', 'La Charité', 'Nérac', 'Bitche', 'La Ferté-Bernard', 'Toulon', 'Pont-de-Vaux', 'Châtellerault', 'Soissons', 'Noyon', 'Chartres', 'Bourbonne-les-Bains', 'Crépy', 'Autun', 'Mauléon', 'Mirande', 'Tartas', 'Douai', 'Poitiers', 'Clamecy', 'Mirecourt', 'Vihiers', 'Nogent-Le-Rotrou', 'Janville', 'Céret', 'Nevers', 'Digne', 'Mer', 'Saint-Claude', 'Brest', \"L'Isle-Jourdain\", 'Saint-Gaudens', 'Pontoise', 'Montlieu', 'Limoux', 'Strasbourg', 'Embrun', 'Fougères', 'Monflanquin', 'Calais', 'Provins', 'Montdidier', 'Saint-Marcellin', 'Bourges', 'Falaise', 'Vico', 'Caen', 'Barcelonnette', 'Fresnay-sur-Sarthes', 'Mur-de-Barrez', 'Saint-Rambert', 'Tulle', 'Arcis-sur-Aube', 'Chauny', 'La Rochefoucauld', 'Evreux', 'Vesoul', \"Pont-l'Evêque\", 'Crest', 'Vendôme', 'Loches', 'La Guerche', 'Mont-de-Marsan', 'Montmorillon', 'Corbeil', 'Avesnes', 'Villefort', 'Neuville-aux-Bois', 'Grand-Andelys', 'Cany', 'Guérêt', \"Saint-Jean-d'Angély\", 'Bazas', 'Nogaro', 'Breteuil', 'Amiens', 'Altkirch', 'Bellême', 'Melun', 'Commercy', 'Cervione', 'Lamarche', 'Oloron', 'Rodez', 'Saint-Céré AND Figeac', 'Brignoles', 'Argelès', 'Lisieux', 'Barbezieux', 'Amboise', 'Château-Thierry', 'Trévoux', 'Lesparre', 'Apt', 'Saint-Florentin', 'Meyrueis', 'Broons', 'Châteaudun', 'Châtillon-sur-Seine', 'Charolles', 'Thouars', 'Bergerac', 'Lure', 'Monistrol', 'Tonneins', 'Le Blanc', 'Mamers', 'Château-du-Loir', 'Blamont', 'Cognac', 'Billom', 'Gex', 'Laon', 'Etampes', 'Tournon Le Mézenc', 'Le Faouët', 'Dinan', 'Loudéac', 'Bruyères', 'Saint-Flour', 'Sens', 'Wissembourg', 'Challans', 'Saint-Chély', 'Bellac', 'Jussey', 'Paris', 'Ajaccio', 'Pithiviers', 'Bar-le-Duc', 'Cadillac', 'Joyeuse La Tanargue', 'Verdun', 'Carentan', 'Lagrasse', 'Loudun', 'Sancoins', 'Redon', 'Bourg', 'Ploërmel', 'Cosne', 'Valenciennes', 'Saint-Pol', 'Serres', 'Riom', 'Montmarault', 'Bellay', 'Avallon', 'Vire', 'Montivilliers', 'La Porta', 'Romorantin', 'Grandpré', 'Saint-Leonard', 'Cérilly', 'Bain', 'Sancerre', 'Ruffec', 'Alençon', 'Montaigu', 'La Roche-Bernard', 'Montbrisson', 'Roanne', 'Bar-sur-Aube', 'Tallano', 'Bernay', 'Remiremont', 'Saint-Denis', 'Hazebrouck', 'Gap', 'Confolens', 'Châlons', 'Tours', 'Langogne', 'Evaux', 'Perpignan', 'Ernée', 'Benfeld', 'Montreuil', 'Sedan', 'Langeais', 'Aubusson', 'La-Barthe-de-Neste', 'Béthune', 'Gaillac', 'Saint-Paul', 'Sarlat', 'Figeac', 'Florac', 'Ribérac', 'Dieuze', 'Bar-sur-Seine', 'Aurillac', 'Mirepoix', 'Mondoubleau', 'Josselin', 'Saint-Aignan', 'Dieppe', 'Ussel', 'Aubigny', 'Chateau-Renault', 'Machecoul', 'Gray', 'Versailles', 'Grasse', 'Libourne', 'Châteauroux', 'Castres', 'Marcigny', 'Arles', 'Marennes', 'Lectoure', 'Saint-Maximin', 'Narbonne', 'Saint-Affrique', 'Caudebec', 'Excideuil', 'Cholet', 'Lauzun', 'Belvès', 'Pont-Audemer', 'Saint-Yrieix', 'Rethel', 'Romans', 'Besse', 'Montluel', 'Coutances', 'Darney', 'Epinal', 'Dreux', 'Chateaubriant', 'Privas', 'Guérande', 'Orleans', 'Château-Salins', 'Moulins', 'La Rochelle', 'Saint-Dizier', 'Angers', 'Argenton', 'Saint-Germain', 'Carhaix', 'Mende', 'Ile-Rousse', 'Corte', 'Orthez', 'Vaucouleurs', 'Lacaune', 'Clermont-en-Argonne', 'Saint-Palais', \"Saint-Geniez-de-Rive-d'Olt\", 'Chateauneuf', 'Baugé', 'Bourganeuf', 'Château-Chinon', 'Vierzon', 'Muret', 'Luxeuil', 'Sillé-le-Guillaume', 'Bourg-en-Bresse', 'Bourmont', 'Rozay', 'Lavaur', 'Charleville', 'Beaucaire', 'Sisteron', 'Pont-à-Mousson', 'Dax', 'Fréjus', 'Is-sur-Tille', 'Bordeaux', 'Belfort', 'Saint-Amand', 'Savenay', 'Boulogne', 'Lusignan', 'Châteaumeillant', 'Pons', 'Nemours', 'Saint-Calais', 'Colmar', 'Montauban', 'La-Tour-du-Pin', 'Châtillon-sur-Indre', 'Marseille', 'Grenade', 'Marmande', 'Saint-Florent-le-Vieil', 'Sauveterre', 'Nogent-sur-Seine', 'Joigny', 'Montargis', 'Nyons', 'Arnay-le-Duc', 'Vitry-le-François', 'Pont Saint-Esprit', 'Saint-Junien', 'Draguignan', 'Casteljaloux', 'Montignac', 'Stenay', 'Lunéville', 'Montluçon', 'Melle', 'Clisson', 'Sablé', 'Lauzerte', 'Saint-Maixent', 'Brive-la-Gaillarde', 'Joinville', 'Châtillon-sur-Saône', 'Tarbes', 'Neufchâteau', 'Domfront', 'Briey', 'Castellane', 'Gournay', 'Castelsarrasin', 'Le Puy', 'Mauriac', 'Vannes', 'Paimbeuf', 'Montélimar', 'Ustarritz', 'Mâcon', 'Nimes', 'Agen', 'Saint-Quentin', 'Murat', 'Quingey', 'Dijon', 'Louviers', 'Vienne', 'Chaumont', 'Etain', 'Saint-Omer', 'Cherbourg', 'Sainte-Sever', 'Auxerre', 'Le Donjon', 'Mussidan', 'Dol', 'La Flèche', 'Bourbon-Lancy', 'Barjols', 'Epernay', \"Villeneuve-d'Agen\", 'Aubin', 'Vitré', 'Prades', 'Pau', 'Châteauneuf', 'Tonnerre', 'Poligny', 'Doullens', 'Vervins', 'Foix', 'Rennes', 'Château-Gontier', 'Blain', 'Châteaulin', 'Le Quesnoy', 'Revel', 'Thionville', 'Orgelet', 'Nantes', 'Millau', 'Haguenau', 'Parthenay', 'Saint-Brieuc', 'Issoudun', 'Blois', 'Toulouse', 'Le Dorat', 'Langres', 'Metz', \"L'Aigle\", 'Sarrelouis', 'Saint-Jean-de-Losne', 'Bourg-la-Reine', 'Vouziers', 'Sommières', 'Saint-Céré', 'La Châtaigneraie', 'Pontrieux', 'Lamballe', 'Rouen', 'Saint-Hippolyte', 'Mortain', 'Uzès', 'Evron', 'Die', 'Bastia', 'Issoire', 'Uzerche', 'Sainte-Menehould', 'Boussac', 'Nontron', 'Brioude', 'Le Mans', 'Bapaume', 'Saumur', 'Besançon', 'Saint-Mihiel', 'Chinon', 'Bayeux', 'Saintes', 'Decize', 'Fontenay-le-Comte', 'Péronne', 'Valognes', 'Saint-Girons', 'Arbois', 'Grandvilliers', 'Rostrenen', 'Verneuil', 'Lesneven', 'Cahors', 'Condom', 'Saint-Lô', 'Cusset', 'Limoges', 'Toul', 'Lyon', 'Avranches', 'Thiers', 'Corbigny', 'Felletin', 'Pontecroix', 'Beaugency', 'Lille', 'Auray', 'Longwy', 'Vic-Bigorre', 'Ornans', 'Nancy', 'Saint-Fargeau', 'Béziers', 'Montaigut', 'Morlaix', 'Clermont', 'Reims', 'Neufchâtel', 'Hennebont', 'Salon-de-Provence', 'Saint-Malo', 'Ancenis', 'Saint-Pons-de-Thomières', 'Semur-en-Auxois', 'Abbeville', 'Pontivy', 'Gien', 'Argentan', 'Rocroi', 'Briançon', 'Castelnaudary', 'Auch', 'Beauvais', 'Tarascon', 'Saint-Pierre-le-Moûtier', 'Vézelise', 'Mantes', 'Gomesse', 'Châlon-sur-Saône', 'Meaux', 'Angoulême', \"Les Sables-d'Olonne\", 'Lons-le-Saunier', 'Arras', 'Mortagne', 'Aix-en-Provence', 'Séverac-le-Château', 'Lannion', 'Montpellier', 'Quillan', 'Boulay', 'Clermont-Ferrand', 'Le vigan', 'Dourdan', 'Carcassonne', 'Sézanne', 'Quimper', 'Laval', 'La Roche-sur-Yon', 'Rieux', 'Compiègne', 'Louhans', 'Preuilly', 'Civray', 'Landerneau', 'Rambervilliers', 'Villaines', 'Sarreguemines', 'Baume-les-Dames', 'Champlitte', 'Gourdon', 'Boiscommun', 'Saint-Etienne', 'Nantua', 'Ambert', 'La Châtre', 'Bergues', 'La Réole', 'Beaune', 'Niort', 'Gannat', 'Orange', 'Oletta', 'Hyères', 'Pontarlier', 'Guimgamp', 'Quimperlé', 'Cambrai', 'Albi', 'Mayenne', 'Bagnères-de-Bigorre', 'Saint-Giirons', 'Dôle', 'Troyes', 'Châtillon-les-Dombes', 'Craon', 'Marvejols', 'Périgueux', 'Forcalquier', 'Ervy', 'Saint-Dié', 'Grenoble', 'Morhange', 'Sarrebourg', 'Senlis', 'Lodève', 'Montfort', 'Rochefort', 'Villefranche', 'Valence', 'Montbrison', 'Montélimard', 'Menton', 'Delémont', 'Senones', 'Lodèye', 'Saint-Jean-de-Maurienne', 'rocroi', 'Montbéliard', 'Chambéry', 'Carouge', 'Mézières', 'Moutiers', 'Thonon', 'Avignon', 'Carpentras', 'Neu-Saarwerden', 'Neu-Sarrewerden', 'Puget-Théniers', 'Porrentruy', 'Cluses', 'Nice', 'Annecy', 'Creuse', 'Gard', 'Nièvre', 'Maine-et-Loire', 'Lot-et-Garonne', 'Moselle', 'Sarthe', 'Var', 'Ain', 'Aisne', 'Oise', 'Eure-et-Loir', 'Haute-Marne', 'Saône-et-Loire', 'Pyrénées-Atlantiques', 'Gers', 'Landes', 'Nord', 'Vosges', 'Pyrénées-Orientales', 'Alpes-de-Haute-Provence', 'Loir-et-Cher', 'Jura', 'Finistère', 'Haute-Garonne', 'Seine-et-Oise', 'Charente-Maritime', 'Aude', 'Bas-Rhin', 'Hautes-Alpes', 'Ille-et-Vilaine', 'Pas-de-Calais', 'Seine-et-Marne', 'Somme', 'Isère', 'Cher', 'Calvados', 'Corse', 'Aveyron', 'Corrèze', 'Aube', 'Charente', 'Eure', 'Haute-Saône', 'Drôme', 'Indre-et-Loire', 'Lozère', 'Loiret', 'Seine-Maritime', 'Gironde', 'Haut-Rhin', 'Orne', 'Meuse', 'Lot', 'Hautes-Pyrénées', 'Bouches-du-Rhône', 'Yonne', \"Côtes-d'Armor\", \"Côte-d'Or\", 'Deux-Sèvres', 'Dordogne', 'Haute-Loire', 'Indre', 'Meurthe-et-Moselle', 'Puy-De-Dôme', 'Ardèche', 'Morbihan', 'Cantal', 'Vendée', 'Haute-Vienne', 'Manche', 'Allier', 'Ardennes', 'Rhône-et-Loire', 'Marne', 'Tarn', 'Alpes-Maritimes','Alpes Maritimes', 'Ariège', 'Loire-Atlantique', 'Doubs', 'Hérault', 'Drome', 'Loire', 'Golo', 'Vaucluse', 'Mont-Terrible', 'Liamone', 'Mont-Blanc', 'Rhône', 'Seine & Oise', 'Seine & Marne', 'Seine-Inférieure', 'Seine - Inférieure','Seine- Inférieure', 'Léman', 'Côtes-du-Nord'\n",
    "         ]\n",
    "structures_locales = [\"canton\", \"administration municipale\", \"assemblée communale\"]\n",
    "patt = []\n",
    "#lemme-ADP-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"ADP\"}, \n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_adp_lemme)\n",
    "\n",
    "#lemme-DET-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"}, \n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_lemme)\n",
    "        \n",
    "#lemme-ADP-DET-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_adp_det_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"ADP\"},  \n",
    "                 {\"POS\": \"DET\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_adp_det_lemme)\n",
    "        \n",
    "#lemme-DET-ADP-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"},  \n",
    "                 {\"POS\": \"ADP\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_adp_lemme)\n",
    "\n",
    "#lemme-DET-DET-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_det_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"},  \n",
    "                 {\"POS\": \"DET\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_det_lemme)\n",
    "\n",
    "#Lemme-ADP-ADP-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_adp_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"ADP\"},  \n",
    "                 {\"POS\": \"ADP\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_adp_adp_lemme)\n",
    "\n",
    "#structures_locales-ADP-nom propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_adp = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_adp)\n",
    "\n",
    "#structures_locales_DET-nom propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_det = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_det)\n",
    "\n",
    "#structures_locales_ADP_DET_ nom propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_adp_det = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_adp_det)\n",
    "\n",
    "#structures_locales_ADP_ADP_nom_propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_adp_adp = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_adp_adp)\n",
    "\n",
    "#structures_locales_DET_ADP_nom_propre\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"},  \n",
    "                 {\"POS\": \"ADP\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_adp_lemme)\n",
    "\n",
    "#structures_locales_DET_DET_nom_propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_det_det = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_det_det)\n",
    "\n",
    "#inversion_du_sujet_DET\n",
    "for adm in structures_adm:\n",
    "    for adm2 in structures_adm2:\n",
    "        patt_inversion_du_sujet1 = {\n",
    "            \"label\": \"GPE\",\n",
    "            \"pattern\": [\n",
    "            {\"POS\": \"PROPN\"},\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"TEXT\": adm2},\n",
    "            ],\n",
    "        }\n",
    "        patt.append(patt_inversion_du_sujet1)\n",
    "        \n",
    "#inversion_du_sujet_ADP\n",
    "for adm in structures_adm:\n",
    "    for adm2 in structures_adm2:\n",
    "        patt_inversion_du_sujet2 = {\n",
    "            \"label\": \"GPE\",\n",
    "            \"pattern\": [\n",
    "            {\"POS\": \"PROPN\"},\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"TEXT\": adm2},\n",
    "            ],\n",
    "        }\n",
    "        patt.append(patt_inversion_du_sujet2)\n",
    "        \n",
    "nlp_ner = spacy.load(\"output/model-best\")\n",
    "\n",
    "#Ajout d'une règle spéciale pour les traits d'union (Hyphens)\n",
    "infixes = nlp_ner.Defaults.prefixes + ([r\"[./]\", r\"[-]~\", r\"[&]~\", r\"(.'.)\"])\n",
    "infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "\n",
    "nlp_ner.tokenizer = custom_tokenizer(nlp_ner)\n",
    "\n",
    "#Déplacement de l'entity ruler avant la NER (priorisation de l'entity ruler)\n",
    "ruler = nlp_ner.add_pipe(\"entity_ruler\", before=\"ner\")\n",
    "ruler.add_patterns(patt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_ents(doc): \n",
    "    if doc.ents: \n",
    "        for ent in doc.ents: \n",
    "            print(ent.text+' - ' +str(ent.start_char) +' - '+ str(ent.end_char) +' - '+ent.label_+ ' - '+str(spacy.explain(ent.label_))) \n",
    "            print(\"\\n\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour comparer notre premier modèle avec le modèle de NLP original\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.fr.lemmatizer.FrenchLemmatizer at 0x1afc3dc6140>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_ner.add_pipe(\"morphologizer\", source=spacy.load(\"fr_core_news_md\"), before=\"entity_ruler\")\n",
    "nlp_ner.add_pipe(\"parser\", source=spacy.load(\"fr_core_news_md\"), before=\"entity_ruler\")\n",
    "nlp_ner.add_pipe(\"attribute_ruler\", source=spacy.load(\"fr_core_news_md\"), before=\"entity_ruler\")\n",
    "nlp_ner.add_pipe(\"lemmatizer\", source=spacy.load(\"fr_core_news_md\"), before=\"entity_ruler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison entre le NLP_NER que l'on a entraîné et le NLP de base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_nouveau_corpus/urgence2.jsonl', encoding='utf-8') as f:\n",
    "    test_dataset = [json.loads(jline) for jline in f.read().splitlines()]\n",
    "for test in test_dataset[1:20]:\n",
    "    text = test['text']\n",
    "    doc = nlp_ner(text)\n",
    "    show_ents(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_nouveau_corpus/urgence2.jsonl', encoding='utf-8') as f:\n",
    "    test_dataset = [json.loads(jline) for jline in f.read().splitlines()]\n",
    "for test in test_dataset[1:20]:\n",
    "    text = test['text']\n",
    "    doc = nlp(text)\n",
    "    show_ents(doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
