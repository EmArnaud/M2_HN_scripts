{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ce fichier est la version en cours du script de pré-processing du corpus d'entraînement, avant annotation. Il vise à prendre en entrée l'ensemble des décrets d'urgences, les transformer en docs spacy, et les faire ressortir en JSONL pour les corriger dans Doccano.  Il comprend également un script de détection des erreurs de datation dans les XML (passés en dataframe) et créé 10 sous-groupes des décrets d'urgences pour l'annotation sur doccano online (heroku)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports et initialisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.util import compile_prefix_regex, compile_infix_regex, compile_suffix_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "structures_adm = [\"commune\", \"Commune\", \"district\", \"Département\", \"département\", \"départemens\", \"Départemens\", \"municipalité\", \"Municipalité\", \"ville\", \"village\", \"canton\"\n",
    "         ]\n",
    "structures_adm2 = [\"commune\", \"Commune\", \"district\", \"Département\", \"département\", \"départemens\", \"Départemens\", \"municipalité\", \"Municipalité\", \"ville\", \"village\", \"canton\"\n",
    "         ]\n",
    "lieux = ['Basse-Alpes', 'Maine-&-Loire', 'Seine', 'Alpes-maritimes', 'Arriége', 'Charente-inférieure', 'Côte-d\\'or', 'Côtes-du-Nord', 'Dyle', 'Escaut', 'Finistère', 'Forêts', 'Haute-Garonne', 'Ille-et-vilaine', 'Indre-et-Loire', 'Jemmapes', 'Loire-inférieure', 'Lys', 'Meurthe', 'Meuse-inférieure', 'Deux-Nèthes', 'Ourthe', 'Puy-de-Dôme', 'Basses-Pyrénées', 'Pyrénées-Orientales', 'Sambre-et-Meuse', 'Haute-Saone', 'Saone-et-Loire', 'Seine-inférieure', 'Deux-Sèvres', 'La Souterraine', 'Alès', 'Moulins-Engilbert', 'Segré', 'La Charité', 'Nérac', 'Bitche', 'La Ferté-Bernard', 'Toulon', 'Pont-de-Vaux', 'Châtellerault', 'Soissons', 'Noyon', 'Chartres', 'Bourbonne-les-Bains', 'Crépy', 'Autun', 'Mauléon', 'Mirande', 'Tartas', 'Douai', 'Poitiers', 'Clamecy', 'Mirecourt', 'Vihiers', 'Nogent-Le-Rotrou', 'Janville', 'Céret', 'Nevers', 'Digne', 'Mer', 'Saint-Claude', 'Brest', \"L'Isle-Jourdain\", 'Saint-Gaudens', 'Pontoise', 'Montlieu', 'Limoux', 'Strasbourg', 'Embrun', 'Fougères', 'Monflanquin', 'Calais', 'Provins', 'Montdidier', 'Saint-Marcellin', 'Bourges', 'Falaise', 'Vico', 'Caen', 'Barcelonnette', 'Fresnay-sur-Sarthes', 'Mur-de-Barrez', 'Saint-Rambert', 'Tulle', 'Arcis-sur-Aube', 'Chauny', 'La Rochefoucauld', 'Evreux', 'Vesoul', \"Pont-l'Evêque\", 'Crest', 'Vendôme', 'Loches', 'La Guerche', 'Mont-de-Marsan', 'Montmorillon', 'Corbeil', 'Avesnes', 'Villefort', 'Neuville-aux-Bois', 'Grand-Andelys', 'Cany', 'Guérêt', \"Saint-Jean-d'Angély\", 'Bazas', 'Nogaro', 'Breteuil', 'Amiens', 'Altkirch', 'Bellême', 'Melun', 'Commercy', 'Cervione', 'Lamarche', 'Oloron', 'Rodez', 'Saint-Céré AND Figeac', 'Brignoles', 'Argelès', 'Lisieux', 'Barbezieux', 'Amboise', 'Château-Thierry', 'Trévoux', 'Lesparre', 'Apt', 'Saint-Florentin', 'Meyrueis', 'Broons', 'Châteaudun', 'Châtillon-sur-Seine', 'Charolles', 'Thouars', 'Bergerac', 'Lure', 'Monistrol', 'Tonneins', 'Le Blanc', 'Mamers', 'Château-du-Loir', 'Blamont', 'Cognac', 'Billom', 'Gex', 'Laon', 'Etampes', 'Tournon Le Mézenc', 'Le Faouët', 'Dinan', 'Loudéac', 'Bruyères', 'Saint-Flour', 'Sens', 'Wissembourg', 'Challans', 'Saint-Chély', 'Bellac', 'Jussey', 'Paris', 'Ajaccio', 'Pithiviers', 'Bar-le-Duc', 'Cadillac', 'Joyeuse La Tanargue', 'Verdun', 'Carentan', 'Lagrasse', 'Loudun', 'Sancoins', 'Redon', 'Bourg', 'Ploërmel', 'Cosne', 'Valenciennes', 'Saint-Pol', 'Serres', 'Riom', 'Montmarault', 'Bellay', 'Avallon', 'Vire', 'Montivilliers', 'La Porta', 'Romorantin', 'Grandpré', 'Saint-Leonard', 'Cérilly', 'Bain', 'Sancerre', 'Ruffec', 'Alençon', 'Montaigu', 'La Roche-Bernard', 'Montbrisson', 'Roanne', 'Bar-sur-Aube', 'Tallano', 'Bernay', 'Remiremont', 'Saint-Denis', 'Hazebrouck', 'Gap', 'Confolens', 'Châlons', 'Tours', 'Langogne', 'Evaux', 'Perpignan', 'Ernée', 'Benfeld', 'Montreuil', 'Sedan', 'Langeais', 'Aubusson', 'La-Barthe-de-Neste', 'Béthune', 'Gaillac', 'Saint-Paul', 'Sarlat', 'Figeac', 'Florac', 'Ribérac', 'Dieuze', 'Bar-sur-Seine', 'Aurillac', 'Mirepoix', 'Mondoubleau', 'Josselin', 'Saint-Aignan', 'Dieppe', 'Ussel', 'Aubigny', 'Chateau-Renault', 'Machecoul', 'Gray', 'Versailles', 'Grasse', 'Libourne', 'Châteauroux', 'Castres', 'Marcigny', 'Arles', 'Marennes', 'Lectoure', 'Saint-Maximin', 'Narbonne', 'Saint-Affrique', 'Caudebec', 'Excideuil', 'Cholet', 'Lauzun', 'Belvès', 'Pont-Audemer', 'Saint-Yrieix', 'Rethel', 'Romans', 'Besse', 'Montluel', 'Coutances', 'Darney', 'Epinal', 'Dreux', 'Chateaubriant', 'Privas', 'Guérande', 'Orleans', 'Château-Salins', 'Moulins', 'La Rochelle', 'Saint-Dizier', 'Angers', 'Argenton', 'Saint-Germain', 'Carhaix', 'Mende', 'Ile-Rousse', 'Corte', 'Orthez', 'Vaucouleurs', 'Lacaune', 'Clermont-en-Argonne', 'Saint-Palais', \"Saint-Geniez-de-Rive-d'Olt\", 'Chateauneuf', 'Baugé', 'Bourganeuf', 'Château-Chinon', 'Vierzon', 'Muret', 'Luxeuil', 'Sillé-le-Guillaume', 'Bourg-en-Bresse', 'Bourmont', 'Rozay', 'Lavaur', 'Charleville', 'Beaucaire', 'Sisteron', 'Pont-à-Mousson', 'Dax', 'Fréjus', 'Is-sur-Tille', 'Bordeaux', 'Belfort', 'Saint-Amand', 'Savenay', 'Boulogne', 'Lusignan', 'Châteaumeillant', 'Pons', 'Nemours', 'Saint-Calais', 'Colmar', 'Montauban', 'La-Tour-du-Pin', 'Châtillon-sur-Indre', 'Marseille', 'Grenade', 'Marmande', 'Saint-Florent-le-Vieil', 'Sauveterre', 'Nogent-sur-Seine', 'Joigny', 'Montargis', 'Nyons', 'Arnay-le-Duc', 'Vitry-le-François', 'Pont Saint-Esprit', 'Saint-Junien', 'Draguignan', 'Casteljaloux', 'Montignac', 'Stenay', 'Lunéville', 'Montluçon', 'Melle', 'Clisson', 'Sablé', 'Lauzerte', 'Saint-Maixent', 'Brive-la-Gaillarde', 'Joinville', 'Châtillon-sur-Saône', 'Tarbes', 'Neufchâteau', 'Domfront', 'Briey', 'Castellane', 'Gournay', 'Castelsarrasin', 'Le Puy', 'Mauriac', 'Vannes', 'Paimbeuf', 'Montélimar', 'Ustarritz', 'Mâcon', 'Nimes', 'Agen', 'Saint-Quentin', 'Murat', 'Quingey', 'Dijon', 'Louviers', 'Vienne', 'Chaumont', 'Etain', 'Saint-Omer', 'Cherbourg', 'Sainte-Sever', 'Auxerre', 'Le Donjon', 'Mussidan', 'Dol', 'La Flèche', 'Bourbon-Lancy', 'Barjols', 'Epernay', \"Villeneuve-d'Agen\", 'Aubin', 'Vitré', 'Prades', 'Pau', 'Châteauneuf', 'Tonnerre', 'Poligny', 'Doullens', 'Vervins', 'Foix', 'Rennes', 'Château-Gontier', 'Blain', 'Châteaulin', 'Le Quesnoy', 'Revel', 'Thionville', 'Orgelet', 'Nantes', 'Millau', 'Haguenau', 'Parthenay', 'Saint-Brieuc', 'Issoudun', 'Blois', 'Toulouse', 'Le Dorat', 'Langres', 'Metz', \"L'Aigle\", 'Sarrelouis', 'Saint-Jean-de-Losne', 'Bourg-la-Reine', 'Vouziers', 'Sommières', 'Saint-Céré', 'La Châtaigneraie', 'Pontrieux', 'Lamballe', 'Rouen', 'Saint-Hippolyte', 'Mortain', 'Uzès', 'Evron', 'Die', 'Bastia', 'Issoire', 'Uzerche', 'Sainte-Menehould', 'Boussac', 'Nontron', 'Brioude', 'Le Mans', 'Bapaume', 'Saumur', 'Besançon', 'Saint-Mihiel', 'Chinon', 'Bayeux', 'Saintes', 'Decize', 'Fontenay-le-Comte', 'Péronne', 'Valognes', 'Saint-Girons', 'Arbois', 'Grandvilliers', 'Rostrenen', 'Verneuil', 'Lesneven', 'Cahors', 'Condom', 'Saint-Lô', 'Cusset', 'Limoges', 'Toul', 'Lyon', 'Avranches', 'Thiers', 'Corbigny', 'Felletin', 'Pontecroix', 'Beaugency', 'Lille', 'Auray', 'Longwy', 'Vic-Bigorre', 'Ornans', 'Nancy', 'Saint-Fargeau', 'Béziers', 'Montaigut', 'Morlaix', 'Clermont', 'Reims', 'Neufchâtel', 'Hennebont', 'Salon-de-Provence', 'Saint-Malo', 'Ancenis', 'Saint-Pons-de-Thomières', 'Semur-en-Auxois', 'Abbeville', 'Pontivy', 'Gien', 'Argentan', 'Rocroi', 'Briançon', 'Castelnaudary', 'Auch', 'Beauvais', 'Tarascon', 'Saint-Pierre-le-Moûtier', 'Vézelise', 'Mantes', 'Gomesse', 'Châlon-sur-Saône', 'Meaux', 'Angoulême', \"Les Sables-d'Olonne\", 'Lons-le-Saunier', 'Arras', 'Mortagne', 'Aix-en-Provence', 'Séverac-le-Château', 'Lannion', 'Montpellier', 'Quillan', 'Boulay', 'Clermont-Ferrand', 'Le vigan', 'Dourdan', 'Carcassonne', 'Sézanne', 'Quimper', 'Laval', 'La Roche-sur-Yon', 'Rieux', 'Compiègne', 'Louhans', 'Preuilly', 'Civray', 'Landerneau', 'Rambervilliers', 'Villaines', 'Sarreguemines', 'Baume-les-Dames', 'Champlitte', 'Gourdon', 'Boiscommun', 'Saint-Etienne', 'Nantua', 'Ambert', 'La Châtre', 'Bergues', 'La Réole', 'Beaune', 'Niort', 'Gannat', 'Orange', 'Oletta', 'Hyères', 'Pontarlier', 'Guimgamp', 'Quimperlé', 'Cambrai', 'Albi', 'Mayenne', 'Bagnères-de-Bigorre', 'Saint-Giirons', 'Dôle', 'Troyes', 'Châtillon-les-Dombes', 'Craon', 'Marvejols', 'Périgueux', 'Forcalquier', 'Ervy', 'Saint-Dié', 'Grenoble', 'Morhange', 'Sarrebourg', 'Senlis', 'Lodève', 'Montfort', 'Rochefort', 'Villefranche', 'Valence', 'Montbrison', 'Montélimard', 'Menton', 'Delémont', 'Senones', 'Lodèye', 'Saint-Jean-de-Maurienne', 'rocroi', 'Montbéliard', 'Chambéry', 'Carouge', 'Mézières', 'Moutiers', 'Thonon', 'Avignon', 'Carpentras', 'Neu-Saarwerden', 'Neu-Sarrewerden', 'Puget-Théniers', 'Porrentruy', 'Cluses', 'Nice', 'Annecy', 'Creuse', 'Gard', 'Nièvre', 'Maine-et-Loire', 'Lot-et-Garonne', 'Moselle', 'Sarthe', 'Var', 'Ain', 'Aisne', 'Oise', 'Eure-et-Loir', 'Haute-Marne', 'Saône-et-Loire', 'Pyrénées-Atlantiques', 'Gers', 'Landes', 'Nord', 'Vosges', 'Pyrénées-Orientales', 'Alpes-de-Haute-Provence', 'Loir-et-Cher', 'Jura', 'Finistère', 'Haute-Garonne', 'Seine-et-Oise', 'Charente-Maritime', 'Aude', 'Bas-Rhin', 'Hautes-Alpes', 'Ille-et-Vilaine', 'Pas-de-Calais', 'Seine-et-Marne', 'Somme', 'Isère', 'Cher', 'Calvados', 'Corse', 'Aveyron', 'Corrèze', 'Aube', 'Charente', 'Eure', 'Haute-Saône', 'Drôme', 'Indre-et-Loire', 'Lozère', 'Loiret', 'Seine-Maritime', 'Gironde', 'Haut-Rhin', 'Orne', 'Meuse', 'Lot', 'Hautes-Pyrénées', 'Bouches-du-Rhône', 'Yonne', \"Côtes-d'Armor\", \"Côte-d'Or\", 'Deux-Sèvres', 'Dordogne', 'Haute-Loire', 'Indre', 'Meurthe-et-Moselle', 'Puy-De-Dôme', 'Ardèche', 'Morbihan', 'Cantal', 'Vendée', 'Haute-Vienne', 'Manche', 'Allier', 'Ardennes', 'Rhône-et-Loire', 'Marne', 'Tarn', 'Alpes-Maritimes','Alpes Maritimes', 'Ariège', 'Loire-Atlantique', 'Doubs', 'Hérault', 'Drome', 'Loire', 'Golo', 'Vaucluse', 'Mont-Terrible', 'Liamone', 'Mont-Blanc', 'Rhône', 'Seine & Oise', 'Seine & Marne', 'Seine-Inférieure', 'Seine - Inférieure','Seine- Inférieure', 'Léman', 'Côtes-du-Nord'\n",
    "         ]\n",
    "structures_locales = [\"canton\", \"administration municipale\", \"assemblée communale\"]\n",
    "patt = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de l'entity-ruler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemme-ADP-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"ADP\"}, \n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_adp_lemme)\n",
    "\n",
    "#lemme-DET-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"}, \n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_lemme)\n",
    "        \n",
    "#lemme-ADP-DET-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_adp_det_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"ADP\"},  \n",
    "                 {\"POS\": \"DET\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_adp_det_lemme)\n",
    "        \n",
    "#lemme-DET-ADP-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"},  \n",
    "                 {\"POS\": \"ADP\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_adp_lemme)\n",
    "\n",
    "#lemme-DET-DET-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_det_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"},  \n",
    "                 {\"POS\": \"DET\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_det_lemme)\n",
    "\n",
    "#Lemme-ADP-ADP-lemme\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_adp_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"ADP\"},  \n",
    "                 {\"POS\": \"ADP\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_adp_adp_lemme)\n",
    "\n",
    "#structures_locales-ADP-nom propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_adp = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_adp)\n",
    "\n",
    "#structures_locales_DET-nom propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_det = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_det)\n",
    "\n",
    "#structures_locales_ADP_DET_ nom propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_adp_det = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_adp_det)\n",
    "\n",
    "#structures_locales_ADP_ADP_nom_propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_adp_adp = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_adp_adp)\n",
    "\n",
    "#structures_locales_DET_ADP_nom_propre\n",
    "for adm in structures_adm:\n",
    "    for lieu in lieux:\n",
    "        patt_lemme_det_adp_lemme = {\n",
    "                \"label\": \"GPE\", \n",
    "                \"pattern\": [\n",
    "                 {\"TEXT\": adm},\n",
    "                 {\"POS\": \"DET\"},  \n",
    "                 {\"POS\": \"ADP\"},\n",
    "                 {\"TEXT\": lieu},\n",
    "                ],\n",
    "            }\n",
    "        patt.append(patt_lemme_det_adp_lemme)\n",
    "\n",
    "#structures_locales_DET_DET_nom_propre\n",
    "for adm in structures_locales:\n",
    "    patt_structures_locales_det_det = {\n",
    "        \"label\": \"GPE\",\n",
    "        \"pattern\": [\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"POS\": \"PROPN\"},\n",
    "        ],\n",
    "    }\n",
    "    patt.append(patt_structures_locales_det_det)\n",
    "\n",
    "#inversion_du_sujet_DET\n",
    "for adm in structures_adm:\n",
    "    for adm2 in structures_adm2:\n",
    "        patt_inversion_du_sujet1 = {\n",
    "            \"label\": \"GPE\",\n",
    "            \"pattern\": [\n",
    "            {\"POS\": \"PROPN\"},\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"DET\"},\n",
    "            {\"TEXT\": adm2},\n",
    "            ],\n",
    "        }\n",
    "        patt.append(patt_inversion_du_sujet1)\n",
    "        \n",
    "#inversion_du_sujet_ADP\n",
    "for adm in structures_adm:\n",
    "    for adm2 in structures_adm2:\n",
    "        patt_inversion_du_sujet2 = {\n",
    "            \"label\": \"GPE\",\n",
    "            \"pattern\": [\n",
    "            {\"POS\": \"PROPN\"},\n",
    "            {\"TEXT\": adm},\n",
    "            {\"POS\": \"ADP\"},\n",
    "            {\"TEXT\": adm2},\n",
    "            ],\n",
    "        }\n",
    "        patt.append(patt_inversion_du_sujet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.ner.EntityRecognizer at 0x16a36492d00>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "\n",
    "#Ajout d'une règle spéciale pour les traits d'union (Hyphens)\n",
    "infixes = nlp.Defaults.prefixes + ([r\"[./]\", r\"[-]~\", r\"[&]~\", r\"(.'.)\"])\n",
    "infix_re = spacy.util.compile_infix_regex(infixes)\n",
    "\n",
    "def custom_tokenizer(nlp):\n",
    "    return Tokenizer(nlp.vocab, infix_finditer=infix_re.finditer)\n",
    "\n",
    "nlp.tokenizer = custom_tokenizer(nlp)\n",
    "\n",
    "#Déplacement de l'entity ruler avant la NER (priorisation de l'entity ruler)\n",
    "nlp.remove_pipe(\"ner\")\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(patt)\n",
    "nlp.add_pipe(\"ner\", source=spacy.load(\"fr_core_news_md\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tri des erreurs dans les dates a corriger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_urgence = pd.read_csv('Ensemble_decrets_urgence.tsv', sep='\\t')\n",
    "corpus_urgence[\"date\"] = pd.to_datetime(corpus_urgence[\"date\"])\n",
    "df = corpus_urgence.sort_values(by=\"date\")\n",
    "df_triee = df[df.date.isnull()]\n",
    "\n",
    "#Creation d'une liste de tous les types de décrets pour récupérer les intéressants (suppression des messages non datés par exemple)\n",
    "liste = []\n",
    "for items in df_triee['type de décret'].unique():\n",
    "    liste.append(items)\n",
    "liste_mots_conservés = ['arrete', 'decret', 'articles', 'unknown', 'proclamation', 'declaration', 'Declaration', 'discours', 'Arrêté', 'Décret', 'Déclaration', 'Loi', 'Arrêtés', 'loi', 'acte', 'instruction', 'Proclamation', 'arreie', 'lois', 'decrete', 'acrete', 'decet', 'rapport', 'artete', 'arretes', 'atrete', 'resolution', 'adresse', 'liquidation', 'deliberation', 'autorisation', 'acceptation', 'nomination', 'Decret', 'article', 'Instruction','arrette', 'Arrete', 'avis', 'disposition','approbation','Article','Dispositions']\n",
    "\n",
    "#tri en utilisant la liste des mots conservés prédéfinie \n",
    "df_triee2 = df_triee\n",
    "tri_final = df_triee2.loc[df_triee2['type de décret'].isin(liste_mots_conservés)]\n",
    "tri_final2 = tri_final[tri_final.date.isnull()]\n",
    "\n",
    "#sauvegarde de cette liste de mots triés\n",
    "tri_final2.to_csv('Erreurs_lois.tsv', sep='\\t', encoding=\"utf-8\")\n",
    "\n",
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(df[[\"date\",\"ID\"]])\n",
    "    \n",
    "#au total, 475 erreurs de dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    print(df[[\"date\",\"ID\"]])\n",
    "    \n",
    "#au total, 475 erreurs de dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test avec un pas de 365 + Definition de fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_jsonl(dataframe, nom_fichier):\n",
    "    docs = nlp.pipe(dataframe.texte)\n",
    "    ID_corpus = dataframe.ID\n",
    "    with codecs.open(nom_fichier, 'w', encoding='utf8') as f:\n",
    "        increment = 0\n",
    "        for doc in docs:\n",
    "            text = doc.text\n",
    "            labels = []\n",
    "            ID_2 = ID_corpus.iloc[increment]\n",
    "            ID_2_count = len(ID_2)\n",
    "            IDs = (ID_2)\n",
    "            if (len(doc.ents) > 0):\n",
    "                for ent in doc.ents:\n",
    "                    labels.append([ent.start_char+ID_2_count, ent.end_char+ID_2_count, ent.label_])\n",
    "            if (len(labels) > 0):\n",
    "                sentence = {\"text\": IDs + text, \"labels\": labels}    \n",
    "            else:\n",
    "                sentence = {\"text\": IDs + text}\n",
    "            json_string = json.dumps(sentence, ensure_ascii=False)\n",
    "            increment += 1\n",
    "            f.write(json_string)\n",
    "            f.write(\"\\n\")\n",
    "    f.close()\n",
    "    print(nom_fichier, 'exporté')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_urgence = pd.read_csv('Ensemble_decrets_urgence.tsv', sep='\\t')\n",
    "urgence_1 = corpus_urgence[0:365]\n",
    "urgence_2 = corpus_urgence[366:750]\n",
    "urgence_3 = corpus_urgence[751:1095]\n",
    "urgence_4 = corpus_urgence[1096:1460]\n",
    "urgence_5 = corpus_urgence[1461:1825]\n",
    "urgence_6 = corpus_urgence[1826:2190]\n",
    "urgence_7 = corpus_urgence[2191:2555]\n",
    "urgence_8 = corpus_urgence[2556:2920]\n",
    "urgence_9 = corpus_urgence[2921:3285]\n",
    "urgence_10 = corpus_urgence[3286:3650]\n",
    "urgence_11 = corpus_urgence[3651:3707]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ATTENTION : l'entrée suivante a un grand coût d'exécution !\n",
    "###  Prévoir environ 2 heures pour terminer l'exécution de la fonction pour tous les sous-corpus créés sur un ordinateur normal (4 coeur, 16go RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_jsonl(urgence_1, \"urgence1.jsonl\")\n",
    "extract_jsonl(urgence_2, \"urgence2.jsonl\")\n",
    "extract_jsonl(urgence_3, \"urgence3.jsonl\")\n",
    "extract_jsonl(urgence_4, \"urgence4.jsonl\")\n",
    "extract_jsonl(urgence_5, \"urgence5.jsonl\")\n",
    "extract_jsonl(urgence_6, \"urgence6.jsonl\")\n",
    "extract_jsonl(urgence_7, \"urgence7.jsonl\")\n",
    "extract_jsonl(urgence_8, \"urgence8.jsonl\")\n",
    "extract_jsonl(urgence_9, \"urgence9.jsonl\")\n",
    "extract_jsonl(urgence_10, \"urgenc10.jsonl\")\n",
    "extract_jsonl(urgence_11, \"urgence11.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
